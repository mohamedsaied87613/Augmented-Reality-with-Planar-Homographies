{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def loadVid(path):\n",
    "\t# Create a VideoCapture object and read from input file\n",
    "\t# If the input is the camera, pass 0 instead of the video file name\n",
    "\tcap = cv2.VideoCapture(path)\n",
    "\n",
    "\t# Check if camera opened successfully\n",
    "\tif (cap.isOpened()== False):\n",
    "\t\tprint(\"Error opening video stream or file\")\n",
    "\n",
    "\ti = 0\n",
    "\t# Read until video is completed\n",
    "\twhile(cap.isOpened()):\n",
    "\t\t# Capture frame-by-frame\n",
    "\t\ti += 1\n",
    "\t\tret, frame = cap.read()\n",
    "\t\tif ret == True:\n",
    "\n",
    "\t\t\t#Store the resulting frame\n",
    "\t\t\tif i == 1:\n",
    "\t\t\t\tframes = frame[np.newaxis, ...]\n",
    "\t\t\telse:\n",
    "\t\t\t\tframe = frame[np.newaxis, ...]\n",
    "\t\t\t\tframes = np.vstack([frames, frame])\n",
    "\t\t\t\tframes = np.squeeze(frames)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# When everything done, release the video capture object\n",
    "\tcap.release()\n",
    "\n",
    "\treturn frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "img_reference = cv2.imread(\"cv_cover.jpg\",0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "frames=loadVid(\"Part 1/book.mov\")\n",
    "panda_frames=loadVid(\"Part 1/ar_source.mov\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def form_A_mat(corres_ref,corres_frame):\n",
    "\tA = np.empty((0,9))\n",
    "\tfor i in range(len(corres_ref)):\n",
    "\t\tu,v=corres_frame[i]\n",
    "\t\tx,y=corres_ref[i]\n",
    "\t\tx=np.array([\n",
    "\t\t\t\t   [-x , -y , -1 , 0 ,0 ,0 ,u*x, u*y , u],\n",
    "\t\t\t\t   [0,0,0,-x,-y,-1,v*x,v*y,v]\n",
    "\t\t\t\t   ])\n",
    "\t\tA = np.vstack( (A,x) )\n",
    "\treturn A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def overlay(img_reference,book_frame,panda_frame,segma=0.4):\n",
    "\n",
    "\tsift = cv2.SIFT_create()\n",
    "\tkp_reference, des_reference = sift.detectAndCompute(img_reference,None)  #GET SIFT DESCRIPTORS AND KEYPOINTS FOR COVER\n",
    "\n",
    "\tkp_frame, des_frame = sift.detectAndCompute(book_frame,None)\n",
    "\n",
    "\t#MATCH DESCRIPTORS IN COVER AND BOOK FRAME\n",
    "\tbf = cv2.BFMatcher()\n",
    "\tmatches = bf.knnMatch(des_reference,des_frame, k=2)\n",
    "\n",
    "\t#FILTER GOOD CORRESPONDANCES AND THEIER COORDINATES\n",
    "\tgood = []\n",
    "\tcorrespondence_reference = []\n",
    "\tcorrespondence_frame = []\n",
    "\tfor m,n in matches:\n",
    "\t\tif m.distance < segma*n.distance:\n",
    "\t\t\tgood.append([m])\n",
    "\t\t\tcorrespondence_reference.append(kp_reference[m.queryIdx].pt)\n",
    "\t\t\tcorrespondence_frame.append(kp_frame[m.trainIdx].pt)\n",
    "\n",
    "\tgood=good[:50]\t#TO PLOT MATCHES\n",
    "\n",
    "\t#GET A TO SOLVE DLT AH=0\n",
    "\tA=form_A_mat(correspondence_reference,correspondence_frame)\n",
    "\tu, s, v = linalg.svd(A)\n",
    "\tDOF=np.reshape(v[-1],(3,3))\n",
    "\n",
    "\n",
    "\tur_pixel=np.matmul(DOF,(img_reference.shape[1],0,1))/np.matmul(DOF,(img_reference.shape[1],0,1))[2]\n",
    "\tul_pixel=np.matmul(DOF,(0,0,1))/np.matmul(DOF,(0,0,1))[2]\n",
    "\tlr_pixel=np.matmul(DOF,(img_reference.shape[1],img_reference.shape[0],1))/np.matmul(DOF,(img_reference.shape[1],img_reference.shape[0],1))[2]\n",
    "\tll_pixel=np.matmul(DOF,(0,img_reference.shape[0],1))/np.matmul(DOF,(0,img_reference.shape[0],1))[2]\n",
    "\n",
    "\t#RESUZIE ROWS\n",
    "\tcol_to_crop=int((panda_frame.shape[1]-img_reference.shape[1])/2)\n",
    "\txx=panda_frame[ : , col_to_crop:panda_frame.shape[1]-col_to_crop, :]\n",
    "\txx=cv2.resize(xx, (350,440))\n",
    "\n",
    "\ttemp_frame=book_frame.copy()\n",
    "\tfor j in range (xx.shape[0]):\n",
    "\t\tfor i in range (xx.shape[1]):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tres=np.matmul(DOF,(i,j, 1))\n",
    "\t\t\t\tres=np.ceil(res/res[2]).astype(int)\n",
    "\t\t\t\ttemp_frame[res[1],res[0],:]=xx[j,i,]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"hi\")\n",
    "\t\t\t\treturn overlay(img_reference,book_frame,panda_frame,segma=segma+0.1)\n",
    "\n",
    "\treturn temp_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "for i in range(len(panda_frames)):\n",
    "\timg=overlay(img_reference,frames[i].copy(),panda_frames[i].copy(),segma=0.4)\n",
    "\tcv2.imwrite(\"saved/img_\"+str(i)+\".jpg\", img)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
