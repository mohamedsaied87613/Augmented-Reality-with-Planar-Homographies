{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def loadVid(path):\n",
    "\t# Create a VideoCapture object and read from input file\n",
    "\t# If the input is the camera, pass 0 instead of the video file name\n",
    "\tcap = cv2.VideoCapture(path)\n",
    "\n",
    "\t# Check if camera opened successfully\n",
    "\tif (cap.isOpened()== False):\n",
    "\t\tprint(\"Error opening video stream or file\")\n",
    "\n",
    "\ti = 0\n",
    "\t# Read until video is completed\n",
    "\twhile(cap.isOpened()):\n",
    "\t\t# Capture frame-by-frame\n",
    "\t\ti += 1\n",
    "\t\tret, frame = cap.read()\n",
    "\t\tif ret == True:\n",
    "\n",
    "\t\t\t#Store the resulting frame\n",
    "\t\t\tif i == 1:\n",
    "\t\t\t\tframes = frame[np.newaxis, ...]\n",
    "\t\t\telse:\n",
    "\t\t\t\tframe = frame[np.newaxis, ...]\n",
    "\t\t\t\tframes = np.vstack([frames, frame])\n",
    "\t\t\t\tframes = np.squeeze(frames)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# When everything done, release the video capture object\n",
    "\tcap.release()\n",
    "\n",
    "\treturn frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "img_reference = cv2.imread(\"Part 1/cv_cover.jpg\",0)\n",
    "frames=loadVid(\"Part 1/book.mov\")\n",
    "panda_frames=loadVid(\"Part 1/ar_source.mov\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def overlay(img_reference,book_frame,panda_frame,segma=0.2 , min_correspondences=30):\n",
    "\n",
    "\tsift = cv2.SIFT_create()\t#CREATE SIFT OBJECT\n",
    "\n",
    "\t#GET SIFT DESCRIPTORS AND KEYPOINTS FOR COVER IMAGE (REFERENCE)\n",
    "\tkp_reference, des_reference = sift.detectAndCompute(img_reference,None)\n",
    "\tkp_frame, des_frame = sift.detectAndCompute(book_frame,None)\n",
    "\n",
    "\t#MATCH DESCRIPTORS BETWEEN COVER(REFERENCE) AND BOOK_FRAME\n",
    "\tbf = cv2.BFMatcher()\n",
    "\tmatches = bf.knnMatch(des_reference,des_frame, k=2)\n",
    "\n",
    "\t#FILTER GOOD CORRESPONDANCES WITH\n",
    "\t# MIN NU OF CORRESPONDENCES = MIN_CORRES  , DISTANCE RATIO BETWEEN 2 MATCHES (KNN) = SEGMA\n",
    "\t# AND GET THEIER COORDINATES\n",
    "\tcorrespondence_reference = []\n",
    "\tcorrespondence_frame = []\n",
    "\twhile len(correspondence_frame)<min_correspondences:\n",
    "\t\tcorrespondence_reference = []\n",
    "\t\tcorrespondence_frame = []\n",
    "\n",
    "\t\tfor m,n in matches:\n",
    "\t\t\tif m.distance < segma*n.distance:\n",
    "\t\t\t\tcorrespondence_reference.append(kp_reference[m.queryIdx].pt)\n",
    "\t\t\t\tcorrespondence_frame.append(kp_frame[m.trainIdx].pt)\n",
    "\t\tsegma=segma+0.005\n",
    "\n",
    "\n",
    "\n",
    "\t#GET A TO SOLVE DLT AH=0\n",
    "\tA = np.empty((0,9))\n",
    "\tfor i in range(len(correspondence_reference)):\n",
    "\t\tu,v=correspondence_frame[i]\n",
    "\t\tx,y=correspondence_reference[i]\n",
    "\t\tx=np.array([\n",
    "\t\t\t\t   [-x , -y , -1 , 0 ,0 ,0 ,u*x, u*y , u],\n",
    "\t\t\t\t   [0,0,0,-x,-y,-1,v*x,v*y,v]\n",
    "\t\t\t\t   ])\n",
    "\t\tA = np.vstack( (A,x) )\n",
    "\tu, s, v = linalg.svd(A)\n",
    "\tDOF=np.reshape(v[-1],(3,3))\t\t#MIN VECTOR\n",
    "\n",
    "\t#ur_pixel=np.matmul(DOF,(img_reference.shape[1],0,1))/np.matmul(DOF,(img_reference.shape[1],0,1))[2]\n",
    "\t#ul_pixel=np.matmul(DOF,(0,0,1))/np.matmul(DOF,(0,0,1))[2]\n",
    "\t#lr_pixel=np.matmul(DOF,(img_reference.shape[1],img_reference.shape[0],1))/np.matmul(DOF,(img_reference.shape[1],img_reference.shape[0],1))[2]\n",
    "\t#ll_pixel=np.matmul(DOF,(0,img_reference.shape[0],1))/np.matmul(DOF,(0,img_reference.shape[0],1))[2]\n",
    "\n",
    "\t#RESIZE ROWS IN PANDA VIDEO FRAME TO FIT ONTO REFERENCE\n",
    "\t#NOTE ROWS VALS (41,44) SELECTED MANUALLY BY OBSERVING THE PANDA_VID FRAMES\n",
    "\n",
    "\tcol_to_crop=int((panda_frame.shape[1]-img_reference.shape[1])/2)\n",
    "\txx=panda_frame[ 44:panda_frame.shape[0]-44 , col_to_crop:panda_frame.shape[1]-col_to_crop, :]\n",
    "\txx=cv2.resize(xx, (350,440))\n",
    "\n",
    "\t#GET COREESPONDING POINT IN BOOK VIDEO FRAME AND OVERLAY PANDA FRAME ON IT\n",
    "\ttemp_frame=book_frame.copy()\n",
    "\tfor i in range (xx.shape[0]):\n",
    "\t\tfor j in range (xx.shape[1]):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tres=np.matmul(DOF,(j,i, 1))\n",
    "\t\t\t\tres=np.ceil(res/res[2]).astype(int)\n",
    "\t\t\t\tif res[0]>=0 and res[1]>=0:\n",
    "\t\t\t\t\ttemp_frame[res[1],res[0],:]=xx[i,j,]\n",
    "\t\t\texcept:\n",
    "\t\t\t\treturn overlay(img_reference,book_frame,panda_frame,min_correspondences=min_correspondences-5)\n",
    "\t#print(\"segma : \", segma)\n",
    "\t#print(\"length : \", len(correspondence_frame))\n",
    "\treturn temp_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#APPLY TRANSFORMATION ON EACH FRAME  PANDA-->BOOK\n",
    "for i in range(len(panda_frames)):\n",
    "\timg=overlay(img_reference,frames[i].copy(),panda_frames[i].copy(),segma=0.11,min_correspondences=50)\n",
    "\tcv2.imwrite(\"saved/\"+str(i)+\".jpg\", img)\n",
    "\n",
    "idle_frames=frames.shape[0]-panda_frames.shape[0]\n",
    "for i in  range(\tpanda_frames.shape[0],idle_frames+panda_frames.shape[0]\t):\n",
    "\timg=overlay(img_reference,frames[i].copy(),panda_frames[-1].copy(),segma=0.11,min_correspondences=50)\n",
    "\tcv2.imwrite(\"saved/\"+str(i)+\".jpg\", img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "path= \"C:\\\\Users\\\\moham\\\\PycharmProjects\\\\pythonProject\\\\saved\\\\\"\n",
    "out_path = \"C:\\\\Users\\\\moham\\\\PycharmProjects\\\\pythonProject\\\\output_video\"\n",
    "out_video_name= '.mp4'\n",
    "out_video_full_path=out_path+out_video_name\n",
    "\n",
    "img = [int(x.split('.')[0]) for x in os.listdir(path)]\n",
    "img.sort()\n",
    "img= [str(x)+'.jpg' for x in img]\n",
    "\n",
    "temp=[]\n",
    "for i in img:\n",
    "\ttemp.append(path+i)\n",
    "\n",
    "cv2_fourcc=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "frame=cv2.imread(img[0])\n",
    "size=list(frames[0].shape)\n",
    "del size[2]\n",
    "size.reverse()\n",
    "\n",
    "video = cv2.VideoWriter(out_video_full_path,cv2_fourcc,30,size)\n",
    "\n",
    "for i in range (len(temp)):\n",
    "\tvideo.write(cv2.imread(temp[i]))\n",
    "video.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
